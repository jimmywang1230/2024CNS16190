{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  langchain langchain-community langchainhub langchain-openai langchain-chroma bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import getpass\n",
    "# import os\n",
    "# import openai\n",
    "\n",
    "\n",
    "# import dotenv\n",
    "\n",
    "# dotenv.load_dotenv()\n",
    "# OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_verbose\n",
    "\n",
    "set_verbose(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from werkzeug.utils import secure_filename\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import uuid\n",
    "import openai\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader, CSVLoader\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain.chains import RetrievalQA, ConversationChain\n",
    "from langchain_community.llms import OpenAI\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_key = OPENAI_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# app = Flask(__name__)\n",
    "# app.config['UPLOAD_FOLDER'] = 'uploads/'\n",
    "# app.config['DATABASE_FOLDER'] = 'database/'\n",
    "# ALLOWED_EXTENSIONS = {'pdf', 'csv'}\n",
    "\n",
    "# if not os.path.exists(app.config['UPLOAD_FOLDER']):\n",
    "#     os.makedirs(app.config['UPLOAD_FOLDER'])\n",
    "\n",
    "# if not os.path.exists(app.config['DATABASE_FOLDER']):\n",
    "#     os.makedirs(app.config['DATABASE_FOLDER'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: database\\CNS16190_correct.pdf\n",
      "Processed file: CNS16190_correct.pdf\n",
      "Processing file: database\\en_303645v020101p.pdf\n",
      "Processed file: en_303645v020101p.pdf\n",
      "Processing file: database\\ts_103701v010101p.pdf\n",
      "Processed file: ts_103701v010101p.pdf\n",
      "Processing file: database\\根據測試項目描述與可應對測試項目的設備功能撰寫的question(Test Scenario).csv\n",
      "Processed file: 根據測試項目描述與可應對測試項目的設備功能撰寫的question(Test Scenario).csv\n",
      "All files in the database folder have been loaded and processed.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader, PyPDFLoader, CSVLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load, chunk and index the contents of the blog.\n",
    "# loader = WebBaseLoader(\n",
    "#     web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "#     bs_kwargs=dict(\n",
    "#         parse_only=bs4.SoupStrainer(\n",
    "#             class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "#         )\n",
    "#     ),\n",
    "# )\n",
    "# docs = loader.load()\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "# splits = text_splitter.split_documents(docs)\n",
    "# vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "ALLOWED_EXTENSIONS = {'pdf', 'csv'}\n",
    "\n",
    "docs = []\n",
    "\n",
    "def allowed_file(filename):\n",
    "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
    "\n",
    "def process_file(filepath):\n",
    "    global docs\n",
    "\n",
    "    _, file_extension = os.path.splitext(filepath)\n",
    "    file_extension = file_extension.lower()\n",
    "\n",
    "    print(f\"Processing file: {filepath}\")\n",
    "    \n",
    "    if file_extension == '.pdf':\n",
    "        loader = PyPDFLoader(filepath)\n",
    "    elif file_extension == '.csv':\n",
    "        loader = CSVLoader(filepath, encoding='utf-8')\n",
    "    else:\n",
    "        print(f\"Unsupported file type: {filepath}\")\n",
    "        return\n",
    "\n",
    "    docs.extend(loader.load_and_split())\n",
    "\n",
    "def load_all_files_from_database():\n",
    "    global docs\n",
    "    database_folder = \"database\"  # 假設你的database文件夾在當前目錄\n",
    "    for filename in os.listdir(database_folder):\n",
    "        if allowed_file(filename):\n",
    "            filepath = os.path.join(database_folder, filename)\n",
    "            process_file(filepath)\n",
    "            print(f\"Processed file: {filename}\")\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "    vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "    return 'All files in the database folder have been loaded and processed.', vectorstore\n",
    "\n",
    "\n",
    "status, vectorstore = load_all_files_from_database()\n",
    "print(status)\n",
    "\n",
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever = vectorstore.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "llm = ChatOpenAI(api_key=OPENAI_API_KEY, model=\"gpt-4\", request_timeout=60)\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
    "which might reference context in the chat history, formulate a standalone question \\\n",
    "which can be understood without the chat history. Do NOT answer the question, \\\n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "\n",
    "qa_system_prompt = \"\"\"您是一位了解CNS16190、EN303645和ETSI TS 103 701的有用助手。\\\n",
    "    使用以下內容來回答最後的問題。如果您不知道答案，只需說您不知道，不要試圖編造答案。\n",
    "    當您被要求生成測試場景時，應該使用三個要素來生成測試場景：\n",
    "    1. 給定的條款號和描述\n",
    "    2. 提供的對應於條款描述的功能\n",
    "    3. 在ETSI TS 103 701中找到對應於條款號和描述的測試場景\n",
    "    \n",
    "    Context: {context}\n",
    "    \"\"\"\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "\n",
    "chat_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNS16190是中華民國的國家標準，專門針對消費者物聯網（Internet of Things, IoT）的網宇安全基準要求進行規範。這份標準主要規定了消費者IoT裝置的網路安全控制措施，例如無通用的預設通行碼、實作管理脆弱性報告的方式、保持軟體更新、安全儲存敏感性安全參數、安全通訊等。\n",
      "\n",
      "其中，標準中的26控制措施6.5條款強調，如果消費者的IoT裝置和服務中蒐集遙測資料，應該向消費者提供有關蒐集哪些遙測資料、如何利用、利用對象及利用目的的資訊。\n",
      "\n",
      "此外，CNS16190也規定了消費者IoT裝置的架構，說明了這些裝置通常是硬體與軟體組件的彙集，具有實體介面或網路介面，並可以直接透過IP連接性連接至LAN，或間接經由閘道器或集線器連接至LAN。該標準還提供了一些測試場景來衡量裝置是否符合CNS16190的要求。\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "\n",
    "\n",
    "question = \"摘要說明 CNS16190 消費者物聯網法規\"\n",
    "ai_msg_1 = rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
    "chat_history.extend([HumanMessage(content=question), ai_msg_1[\"answer\"]])\n",
    "\n",
    "# second_question = \"What are common ways of doing it?\"\n",
    "# ai_msg_2 = rag_chain.invoke({\"input\": second_question, \"chat_history\": chat_history})\n",
    "\n",
    "print(ai_msg_1[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
